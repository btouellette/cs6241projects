\documentclass{article}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage[left=1in,top=1in,right=1in,bottom=1in,nohead]{geometry}

\title{CS6241 Project Phase 1}

\author{Gaurav Gupta, Chad D. Kersey, Brian Ouellette}

\begin{document}

\maketitle

\section{Bounds Check Implementation}

Bounds checking was implemented in two pieces, one inside of the GCC frontend
marks the array accesses and exposes the bounds and index, and another inside of
LLVM takes these annotations and inserts checks. The checks inserted are 
one-sided unsigned comparisons. Since C and C++ arrays can have no starting
index other than zero, casting all indices to unsigned integers and checking the
index against the upper bound will always be sufficient.
\\\\
\noindent All array checks are supported:
\begin{itemize}
\item Arrays of any type
\item Compile-time unknown sized arrays
\item Global arrays
\item n-dimensional arrays
\end{itemize}

\subsection{Modifications to GCC}

The heart of LLVM-GCC is a translator from GCC's IR into LLVM instructions, in
llvm-convert.cpp. 34 lines were added to this file, the modified version of 
which is included in the project submission under llvm-gcc. The lines in 
question are 458-491, in the function responsible for emitting LLVM code for 
array references. A pseudocode version of the added block is presented below:

\begin{verbatim}
  if indexed item is a global or on-stack array:
    upper_bound_cast_instruction = llvm_cast_to_uint64(upper_bound)
    index_cast_instruction = llvm_cast_to_uint64(index)
    
    insert_at_end_of_current_function(upper_bound_cast_instruction)
    insert_at_end_of_current_function(index_cast_instruction)
\end{verbatim}

The upper bound and index are already part of GCC's internal representation, 
GIMPLE, and are readily available as parameters to the indexing operation. The
two casts inserted have no uses and are present only to provide the 
InsertionChecks pass, described in Section \ref{sec:insertion}, with the locations to place
checks and the values to use.

\subsection{InsertChecks Pass}

\label{sec:insertion}

In the LLVM pass, calls into libCheck are added for each array access that was
marked during compile time. A call to 
becomes the sole use for the two \texttt{checkArrayBounds(uint64, uint64)} 
cast instructions. 
Using a subroutine call, on the hardware level, for each array bound check would
be prohibitively slow. InsertChecks relies on LLVM's interprocedural optimizer
to inline each call to \texttt{checkArrayBounds()} so that it becomes only a few
instructions. A subroutine penalty is only encountered when there the bound
check fails, and is only encountered once since this results in program 
termination.
Optimization of instrumentation added by the InsertChecks 
pass is performed by moving or deleting the cast instructions it uses as markers
to add bound checks.

\subsection{Impact}

\begin{itemize}
 \item LAME
  \begin{itemize}
   \item 6.0\% code size increase and 6.1\% execution time increase with no optimization.
   \item Average of 5.97 bytes per bounds check.
  \end{itemize}
  \item mpeg2dec
  \begin{itemize}
   \item 4.6\% code size increase and 42\% run time increase.
   \item Average of 6.83 bytes per bounds check.
  \end{itemize}
\end{itemize}

\section{Bounds Check Pruning}

\label{sec:part2}

\subsection{Constant Removal}

If both the array index and the upper bound are constants then the check can be performed at compile time. Checks that evaluate true are removed from the output code and checks that evaluate false are left in to potentially be revealed at run-time.

\subsection{Local Elimination}

The function is then examined on a basic block level and locally redundant checks are removed. A check is locally redundant if one that is at least as strict as it is performed earlier in the basic block. Since the checks utilized are one-sided comparisons on unsigned numbers some care must be taken when determining what is "more strict" as it depends on whether the upper bound and index are constants or SSA values. Checks are eliminated locally if there is a check with a lower upper bound and identical index or with identical upper bounds and an index between 0 and a previously checked index.

\subsection{Global Elimination}

Global elimination differs from Gupta's paper slightly as monotonicity is not involved and all values are SSA. The choice to use one-sided unsigned checks removes any potential for optimization through exploiting monotonically increasing or decreasing values; however, it reduces the number of checks required by half upfront which results in a number of checks as small as if every check can be exploited using monotonicity. The dataflow equations used to determine whether global elimination is feasible are given below.
\begin{align*}
C\_IN[B_{1}]&=\phi\text{, where } B_{1} \text{ is the initial basic block}\\
C\_IN[B]&=\cap C\_OUT[P]_{P \in Pred(B)}\text{, where Pred(B) is the set of basic blocks that are predecessors of B}\\
C\_OUT[B]&=(C\_IN[B] - C\_KILL[B]) \cup C\_GEN[B]
\end{align*}

Since our target code is already translated to SSA the C\_KILL set will be empty in all situations and C\_GEN is simply the set of checks that are present in each basic block. The C\_IN and C\_OUT sets are computed iteratively until they have stabilized. Then each basic block is examined and any check inside is potentially eliminated by checks that are at least as strict and are present in the C\_IN set. "At least as strict" is implemented in the same way as for local elimination.

\subsection{Propagation of Checks Out of Loops}

\label{sec:loop}

If possible checks will be propagated out of loops to reduce the dynamic check count. Checks may be propagated across multiple levels of loops. Gupta outlines three steps for propagation. First, valid basic blocks from which propagation can be done are marked. Valid blocks will dominate all loop exits. Second, checks in blocks which do not dominate all loop exits are hoisted to blocks which do dominate all loop exits when possible. The algorithm for hoisting is shown below.
\begin{align*}
ND&\text{ - set of nodes which do not dominate all loop exits}\\
C(n)&\text{ - set of checks performed in } n\\
P&\text{ - set of nodes such that for } n \in P, succ(n) \cap ND \neq \phi \text{ and } n \text{ is the unique predecessor of nodes in } succ(n)
\end{align*}
\begin{align*}
\text{while(checks are hoisted):}&\\
\text{Hoist check }& e \text{ into } n \text{ from blocks in } succ(n) \text{ if:}\\
&e \in \cap C(s) _{s \in succ(n)}\\
&n \in P\\
&e \text{ uses same defs in each successor}\\
\end{align*}

Once hoisting has been finished any checks contained in the set of basic blocks which dominate all loop exits are examined for potential propagation out of the loop. Since our approach negates the need to examine monotonicity and our approach in Section \ref{sec:part3} is a superset of the for loop propagation Gupta presents the only checks propagated are those which are loop invariant. Since propagation out of loops enables further global elimination it is performed first.

This algorithm is of limited use for many standard loops. In the CFG representation of while and for loops that LLVM uses the header and the loop exit are the same basic block and also the only basic block within the loop which dominates the loop exit. Since the header has a successor which is outside the loop, only checks which are common to both inside and outside the loop have the potential to be hoisted into the header and thus considered for propagation out of the loop. This scenario is uncommon in normal code constructs.

\section{Further Bounds Check Pruning}

\label{sec:part3}

\subsection{Profiling Infrastructure in libCheck.cpp}

When libCheck.cpp is compiled with the -Ddebug compiler option, a profiling
infrastructure is activated, logging each bounds check's address and the number
of times it is encoutered, and printing the collected addresses and counts, and
a total, after the program exits.

\subsection{The Most Frequent Checks}

The profiling infrastructure, in combinantion with the GNU Debugger, discovered
that the most frequent checks occurred in the inner loop, lines 313 through 315 
of psymodel.c in the following loop:

\begin{verbatim}
308 for ( b = 0;b < npart_s; b++ ) {
309   FLOAT8 norm=0;
310   for ( k = s3ind_s[b][0]; k <= s3ind_s[b][1]; k++ ) {
311     norm += s3_s[b][k];
312   }
313   for ( k = s3ind_s[b][0]; k <= s3ind_s[b][1]; k++ ) {
314     s3_s[b][k] *= SNR_s[b] / norm;
315   }
316   /*printf("%i  norm=%f  norm_s=%f \n",b,1/norm,norm_l[b]);*/
317 }
\end{verbatim}

This single three-line inner loop accounts for 9.94 percent of total dynamic 
array bounds checks, and all of the frequent inner loops have similar form. 
Because b is bounded by npart\_s, which is loop invariant in the outer loop, and
k is  bounded by a value that is loop invariant in the inner loop, all of the 
checks can be hoisted to their respective loop headers as shown in Gupta '93, pages
145-149.

\subsection{Elimination of the Most Frequent Checks}

These types of accesses, though they would have been caught in other cases by
Gupta's loop optimizations, for reasons mentioned in Section \ref{sec:loop}
these optimizations do nothing. For this reason, a new optimization has been
implemented to perform a specific subset of these loop optimizations provided
that, as in the most frequent case:

\begin{itemize}
  \item The induction variable increases monotonically by a constant value.
  \item The induction variable is initialized with a constant or load from an
        address not stored to within the loop.
  \item The loop exits when the induction variable exceeds a bound initialized
        with a constant or load from an address not stored within the loop.
  \item The array index is the loop induction variable.
\end{itemize}

This loop optimization can be applied before any optimization to every array
access within a loop in the program, complicated only by the fact that the
induction variables are typically confined to memory by the compiler. This
implements an important subset of Gupta's loop optimizations on a wider variety
of array accesses, potentially very quickly.

\section{Results of Optimization on \texttt{mpeg2-dec}}

The following table summarizes the impact of the optimizations on code size and execution time using a 38 megabyte MPEG stream file:

\begin{table}[ht]
\caption{Runtime (flags) -- mpeg2dec -b Data/orion\_2.mpg -q -r -f -o0 rec\%d}
\centering
\begin{tabular}{|l|ccc|}
\hline
  \textbf{Optimization Level} & \textbf{File Size (B)}
   & \textbf{Runtime (s)} & \textbf{Norm. Runtime} \\
\hline
Unchecked & 90900 & 43.8 & 1.00 \\
\hline
No Optimization & 95772 & 62.3 & 1.42 \\
\hline
Part 2 Optimization & 95189 & 61.4 & 1.40 \\
\hline
Part 2+3 Optimization & 95125 & 51.7 & 1.18 \\
\hline
\end{tabular}
\end{table}

\begin{table}[ht]
\caption{Runtime (no flags) -- mpeg2dec -b Data/orion\_2.mpg}
\centering
\begin{tabular}{|l|ccc|}
\hline
  \textbf{Optimization Level} & \textbf{File Size (B)} & 
   \textbf{Runtime (s)} & \textbf{Normalized Runtime} \\
\hline
Unchecked & 90900 & 12.6 & 1.00 \\
\hline
No Optimization & 95772 & 13.2 & 1.05 \\
\hline
Part 2 Optimization & 95189 & 13.1 & 1.04 \\
\hline
Part 2+3 Optimization & 95125 & 13.0 & 1.03 \\
\hline
\end{tabular}
\end{table}

The bounds checking significantly impacts runtime of the benchmark, which is no great surprise since most of the benchmark is array accesses. The optimizations implemented in Section \ref{sec:part2} appear to have little effect but that is due to the fact that the LLVM infrastructure is applying a suite of optimizations that partially cover the optimizations implemented. In particular, constant propagation combined with unreachable code elimination is applied which does the same work as the static bounds checks. Global elimination is also partially covered by the global value numbering pass executed in LLVM which removes fully redundant instructions. Some gain is still seen because the concept of strictness is used in our bound check specific version of the optimizations and cannot be in LLVM's version.

The optimizations implemented in Section \ref{sec:part3} are not subject to this redundancy and they operate primarily on the highly profitable inner loops of the benchmark netting a large decrease in runtime. 
\end{document}